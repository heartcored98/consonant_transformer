{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from consonant.model.tokenization import NGRAMTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Num Head Vocab: 17579\nNum Midtail Vocab: 589\n\n Encoding Example : 내가 너 엄청 좋아해?! 히히히 이 기호는 불가능$^*\n=========================\nHead Consonant ID\n0: [PAD], 1: [CLS], 2: [SEP] \n\n[    1   244  6269  4744   237  6105   492 12717 14218   515 13340 12824\n 16985  2135  2732   678 17578 17553 16921   471 12178   210  5394 17137\n  6101   374  9658  4975  6243     2]\n\nMidtail Consonant ID\n[-100   29    1    0  113    0  129  134    0  252    1   29    0    0\n    0  561  561  561    0  561    0  561  225  509    0  373    1  526\n    0 -100]\n\nAttention Mask\n[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n\n Decoding Example\n=========================\nUnknown consonant replaced to @\n\n내가 너 엄청 좋아해?! 히히히 이 기호는 불가능@\n"
    }
   ],
   "source": [
    "sentence = [\"내가 너 엄청 좋아해?! 히히히 이 기호는 불가능$^*\", \"너도 나 좋아하니?\"]\n",
    "tokenizer = NGRAMTokenizer(3)\n",
    "\n",
    "print(\"Num Head Vocab:\", len(tokenizer.head2id))\n",
    "print(\"Num Midtail Vocab:\", len(tokenizer.midtail2id))\n",
    "\n",
    "result = tokenizer.encode(sentence, max_char_length=30, return_attention_mask=True) #, return_tensors='pt')\n",
    "head_ids = result['head_ids']\n",
    "midtail_ids = result['midtail_ids']\n",
    "attention_masks = result['attention_masks']\n",
    "\n",
    "print('\\n Encoding Example :', sentence[0] )\n",
    "print(\"=========================\")\n",
    "\n",
    "print(\"Head Consonant ID\")\n",
    "print(\"0: [PAD], 1: [CLS], 2: [SEP] \\n\")\n",
    "print(head_ids[0])\n",
    "\n",
    "print()\n",
    "print(\"Midtail Consonant ID\")\n",
    "print(midtail_ids[0])\n",
    "\n",
    "print()\n",
    "print(\"Attention Mask\")\n",
    "print(attention_masks[0])\n",
    "\n",
    "print('\\n Decoding Example')\n",
    "print(\"=========================\")\n",
    "print(\"Unknown consonant replaced to @\\n\")\n",
    "\n",
    "result = tokenizer.decode_sent(head_ids[0], midtail_ids[0])\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'간'"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "join_jamos(\"ㄱㅏㄴ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "윮"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bita8f7531970414b1bbdf7938ab7a03f8d",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}