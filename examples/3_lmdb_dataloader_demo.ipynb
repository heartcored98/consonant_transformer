{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single LMDB Subdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import pyxis.torch as pxt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "44689\npyxis.Reader\nLocation:\t\t'../dataset/processed/ratings_3_100/train/1_of_4'\nNumber of samples:\t44689\nData keys (0th sample):\n\t'head_ids' <- dtype: int32, shape: (100,)\n\t'midtail_ids' <- dtype: int32, shape: (100,)\n\t'attention_masks' <- dtype: bool, shape: (100,)\n"
    }
   ],
   "source": [
    "data_dir = \"../dataset/processed\"\n",
    "subset_dir = \"ratings_3_100/train/1_of_4\"\n",
    "sub_dataset = pxt.TorchDataset(os.path.join(data_dir, subset_dir))\n",
    "\n",
    "print(len(sub_dataset))\n",
    "print(sub_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple LMDB ConcatDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Available Chunk list: ['1_of_4', '4_of_4', '3_of_4', '2_of_4']\nFull Dataset Len: 178780\n"
    }
   ],
   "source": [
    "\n",
    "train_data_dir = \"../dataset/processed/ratings_3_100/train\"\n",
    "\n",
    "# We should filter out only directory name excluding all the *.tar.gz files\n",
    "subset_list = [subset_dir for subset_dir in os.listdir(train_data_dir) if os.path.isdir(os.path.join(train_data_dir, subset_dir))]\n",
    "print('Available Chunk list:', subset_list)\n",
    "\n",
    "full_dataset =  ConcatDataset([pxt.TorchDataset(os.path.join(train_data_dir, subset_dir)) for subset_dir in subset_list])\n",
    "print('Full Dataset Len:', len(full_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Available Chunk list: ['3_of_4', '4_of_4', '2_of_4', '1_of_4']\nFull Dataset Len: 19869\n"
    }
   ],
   "source": [
    "\n",
    "train_data_dir = \"../dataset/processed/ratings_3_100/val\"\n",
    "\n",
    "# We should filter out only directory name excluding all the *.tar.gz files\n",
    "subset_list = [subset_dir for subset_dir in os.listdir(train_data_dir) if os.path.isdir(os.path.join(train_data_dir, subset_dir))]\n",
    "print('Available Chunk list:', subset_list)\n",
    "\n",
    "full_dataset =  ConcatDataset([pxt.TorchDataset(os.path.join(train_data_dir, subset_dir)) for subset_dir in subset_list])\n",
    "print('Full Dataset Len:', len(full_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "keys:  dict_keys(['head_ids', 'midtail_ids', 'attention_masks'])\ntensor([[    1,   203,  5213,  ...,     0,     0,     0],\n        [    1,   385,  9935,  ...,     0,     0,     0],\n        [    1,   483, 12483,  ...,     0,     0,     0],\n        ...,\n        [    1,   509, 13178,  ...,     0,     0,     0],\n        [    1,   496, 12828,  ...,     0,     0,     0],\n        [    1,   483, 12483,  ..., 12639, 12171,     2]], dtype=torch.int32)\ntorch.Size([128, 100])\ntensor([[-100,  522,  365,  ..., -100, -100, -100],\n        [-100,  561,  533,  ..., -100, -100, -100],\n        [-100,  561,  117,  ..., -100, -100, -100],\n        ...,\n        [-100,  569,  561,  ..., -100, -100, -100],\n        [-100,  190,  253,  ..., -100, -100, -100],\n        [-100,    1,   29,  ...,  141,    0, -100]], dtype=torch.int32)\ntorch.Size([128, 100])\ntensor([[ True,  True,  True,  ..., False, False, False],\n        [ True,  True,  True,  ..., False, False, False],\n        [ True,  True,  True,  ..., False, False, False],\n        ...,\n        [ True,  True,  True,  ..., False, False, False],\n        [ True,  True,  True,  ..., False, False, False],\n        [ True,  True,  True,  ...,  True,  True,  True]])\ntorch.Size([128, 100])\n"
    }
   ],
   "source": [
    "full_dataloader = DataLoader(full_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "for batch in full_dataloader:\n",
    "    print(\"keys: \", batch.keys())\n",
    "\n",
    "    print(batch['head_ids'])\n",
    "    print(batch['head_ids'].shape)\n",
    "\n",
    "    print(batch['midtail_ids'])\n",
    "    print(batch['midtail_ids'].shape)\n",
    "\n",
    "    print(batch['attention_masks'])\n",
    "    print(batch['attention_masks'].shape)\n",
    "\n",
    "    \n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[-100,  522,  365,  ..., -100, -100, -100],\n        [-100,  561,  533,  ..., -100, -100, -100],\n        [-100,  561,  117,  ..., -100, -100, -100],\n        ...,\n        [-100,  569,  561,  ..., -100, -100, -100],\n        [-100,  190,  253,  ..., -100, -100, -100],\n        [-100,    1,   29,  ...,  141,    0, -100]], dtype=torch.int32)\n"
    }
   ],
   "source": [
    "answer_label = batch['midtail_ids']\n",
    "print(answer_label)\n",
    "torch.sum(answer_label != -100).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python361064bitenvelectraconda1ad35761db5241889e37482be0c5b23a",
   "display_name": "Python 3.6.10 64-bit ('env_electra': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}